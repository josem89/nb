{
    "uniqueIdentifier": "3edcf417-0b26-4afd-b5d7-0c529fd49aa0",
    "id": 0,
    "jobDefinitionId": 0,
    "name": "Sync Azure Sentinel Entities",
    "integration": "MicrosoftAzureSentinel",
    "script": "from SiemplifyJob import SiemplifyJob\nfrom ExtendedMicrosoftAzureSentinelManager import ExtendedMicrosoftAzureSentinelManager\nimport datetime, json, requests, re\nfrom SiemplifyUtils import extract_script_param, utc_now, convert_datetime_to_unix_time, convert_unixtime_to_datetime, unix_now\nfrom TIPCommon import dict_to_flat\n\nTIME_FORMAT = \"%Y-%m-%dT%H:%M:%S.%fZ\"\nINTEGRATION_NAME = \"MicrosoftAzureSentinel\"\nSCRIPT_NAME = \"Sync Azure Sentinel Entities\"\nENTITY_KINDS = [\"Account\", \"File\", \"FileHash\", \"Host\", \"Ip\", \"Url\"]\n\n\ndef create_entities(data,envrionment, siemplify):\n    siemplify.LOGGER.info(f'Creating entities in case {data[\"case_id\"]} - alert {data[\"identifier\"]}')\n    \n    for entity in data[\"entities\"]:\n        try:\n            siemplify.add_entity_to_case(data[\"case_id\"], data[\"identifier\"], entity[\"identifier\"], entity[\"type\"], False, False, False, False, entity[\"properties\"], envrionment)\n            \n        except Exception as e:\n            siemplify.LOGGER.error(f\"Failed to create entity {entity['identifier']}\")\n            siemplify.LOGGER.exception(e)\n    \n    return True\n\ndef process_entities(entities, siemplify):\n   \n   target_entities = []\n   \n   for entity in entities:\n       \n       if entity.kind in ENTITY_KINDS:\n            siemplify.LOGGER.info(f'Processing Entity {entity.name} of kind {entity.kind}')\n            entity_data = {}\n            if entity.kind == \"Account\":\n               entity_data[\"identifier\"] = entity.properties.account_name\n               entity_data[\"type\"] = \"USERUNIQNAME\"\n               entity_data[\"properties\"] = dict_to_flat(entity.properties.raw_data)\n               target_entities.append(entity_data)\n            elif entity.kind == \"Filename\":\n               entity_data[\"identifier\"] = entity.properties.file_name\n               entity_data[\"type\"] = \"FILENAME\"\n               entity_data[\"properties\"] = dict_to_flat(entity.properties.raw_data)\n               target_entities.append(entity_data)\n            elif entity.kind == \"FileHash\":\n               entity_data[\"identifier\"] = entity.properties.hash_value\n               entity_data[\"type\"] = \"FILEHASH\"\n               entity_data[\"properties\"] = dict_to_flat(entity.properties.raw_data)\n               target_entities.append(entity_data)\n            elif entity.kind == \"Host\":\n               entity_data[\"identifier\"] = entity.properties.host_name\n               entity_data[\"type\"] = \"HOSTNAME\"\n               entity_data[\"properties\"] = dict_to_flat(entity.properties.raw_data)\n               target_entities.append(entity_data)\n            elif entity.kind == \"Ip\":\n               entity_data[\"identifier\"] = entity.properties.address\n               entity_data[\"type\"] = \"ADDRESS\"\n               entity_data[\"properties\"] = dict_to_flat(entity.properties.raw_data)\n               target_entities.append(entity_data)\n            elif entity.kind == \"Url\":\n               entity_data[\"identifier\"] = entity.properties.url\n               entity_data[\"type\"] = \"DestinationURL\"\n               entity_data[\"properties\"] = dict_to_flat(entity.properties.raw_data)\n               target_entities.append(entity_data)\n        \n       else:\n           siemplify.LOGGER.info(f'Entity {entity.name} of {entity.kind} kind  not supported. Skipping')\n    \n   return target_entities     \n\n        \ndef calculate_as_time(time):\n    regex = re.compile(r\"(\\.\\d{0,6})(\\d)*(Z)\")\n    time = regex.sub('\\\\1\\\\3',time)\n    _datetime = datetime.datetime.strptime(time, TIME_FORMAT)\n    _datetime = _datetime.replace(tzinfo=datetime.timezone.utc)\n    return _datetime\n    \n\ndef validate_timestamp(last_run_timestamp, offset_in_hours):\n    \"\"\"\n    Validate timestamp in range\n    :param last_run_timestamp: {datetime} last run timestamp\n    :param offset_in_hours: {datetime} last run timestamp\n    :return: {datetime} if first run, return current time minus offset time, else return timestamp from file\n    \"\"\"\n    \n    current_time = utc_now()\n    # Check if first run\n    if current_time - last_run_timestamp > datetime.timedelta(hours=offset_in_hours):\n        valid_timestamp = current_time - datetime.timedelta(hours=offset_in_hours)\n        return valid_timestamp\n        \n    else:\n        return last_run_timestamp\n\n\ndef get_instance_identifier(siemplify,environment,instance_name):\n    url = f\"{siemplify.API_ROOT}/external/v1/integrations/GetOptionalIntegrationInstances\"\n    payload = {\"environments\": [environment],\"integrationIdentifier\": INTEGRATION_NAME}\n    headers = {\"Content-Type\": \"application/json\", \"AppKey\":siemplify.api_key, \"accept\":\"application/json\"}\n    r = requests.post(url,headers=headers, json=payload, verify=False)\n    available_instances = r.json()\n    \n    if instance_name:\n        for instance in available_instances:\n            if instance[\"instanceName\"] == instance_name:\n                return instance[\"identifier\"]\n    else:\n        return available_instances[0][\"identifier\"]\n    \n\ndef main():\n    siemplify = SiemplifyJob()\n    siemplify.script_name = SCRIPT_NAME # In order to use the SiemplifyLogger, you must assign a name to the script.\n    environment = siemplify.extract_job_param(param_name=\"Environment\", print_value=True)\n    instance_name = siemplify.extract_job_param(param_name=\"Instance Name\", print_value=True, default_value=None)\n    hours_back = siemplify.extract_job_param(param_name = \"Hours Back\", print_value=True, default_value=24, input_type = int)\n    tags = siemplify.extract_job_param(param_name = \"Sync Tags\", print_value=True, input_type = str).split(\",\")\n    is_favorite = siemplify.extract_job_param(param_name = \"Only Favorite Comments\", print_value=True, input_type = bool)\n\n    \n    try:\n        siemplify.LOGGER.info(f\"Checking available integrations for {INTEGRATION_NAME} in {environment}\")\n        integration_identifier = get_instance_identifier(siemplify,environment,instance_name)\n        siemplify.LOGGER.info(f\"Using integration Identifier {integration_identifier}\")\n        siemplify.LOGGER.info(f\"Getting integration config details\")\n        integration_settings =  siemplify.get_configuration(INTEGRATION_NAME, environment = environment, integration_instance = integration_identifier)\n        api_root = extract_script_param(siemplify=siemplify, input_dictionary=integration_settings, param_name='Api Root', print_value = True)\n        login_url = extract_script_param(siemplify = siemplify, input_dictionary=integration_settings, print_value = True,\n                                            param_name='OAUTH2 Login Endpoint Url')\n        client_id = extract_script_param(siemplify = siemplify, input_dictionary=integration_settings, print_value = True, param_name='Client ID')\n        client_secret = extract_script_param(siemplify = siemplify, input_dictionary=integration_settings, param_name='Client Secret')\n        tenant_id = extract_script_param(siemplify = siemplify, input_dictionary=integration_settings, print_value = True,\n                                            param_name='Azure Active Directory ID')\n        workspace_id = extract_script_param(siemplify = siemplify, input_dictionary=integration_settings, print_value = True,\n                                               param_name='Azure Sentinel Workspace Name')\n        resource = extract_script_param(siemplify = siemplify, input_dictionary=integration_settings, print_value = True, param_name='Azure Resource Group')\n        subscription_id = extract_script_param(siemplify = siemplify, input_dictionary=integration_settings, print_value = True,\n                                                  param_name='Azure Subscription ID')\n        verify_ssl = extract_script_param(siemplify = siemplify, input_dictionary=integration_settings, print_value = True, param_name='Verify SSL',\n                                             input_type=bool, default_value=False)\n        \n        last_successful_execution_time = siemplify.fetch_timestamp(datetime_format=True, timezone = \"UTC\")\n        last_successful_execution_time = validate_timestamp(last_successful_execution_time, hours_back)\n        last_successful_execution_timestamp = convert_datetime_to_unix_time(last_successful_execution_time)\n        siemplify.LOGGER.info(f\"Fetching Azure Sentinel Incidents updated after {last_successful_execution_time}\")\n        \n        manager = ExtendedMicrosoftAzureSentinelManager(\n            api_root=api_root,\n            client_id=client_id,\n            client_secret=client_secret,\n            tenant_id=tenant_id,\n            workspace_id=workspace_id,\n            resource=resource,\n            subscription_id=subscription_id,\n            login_url=login_url,\n            verify_ssl=verify_ssl\n        )\n        \n        incidents = manager.get_updated_incidents(updated_time = last_successful_execution_time, limit =200)\n        incidents = [incident.to_json() for incident in incidents]\n        \n        siemplify_cases = siemplify.get_cases_by_filter(environments = [environment], tags = tags, statuses = [1])\n        siemplify_alerts = []\n        incidents_list = []\n        \n        if siemplify_cases:\n            for case in siemplify_cases:\n                case_data = siemplify._get_case_by_id(case)\n                \n                for alert in case_data[\"cyber_alerts\"]:\n                    if alert[\"additional_properties\"][\"SourceSystemName\"] == \"MicrosoftAzureSentinel\":\n                        alert_data = {}\n                        alert_data[\"case_id\"] = case_data[\"identifier\"]\n                        alert_data[\"identifier\"] = alert[\"identifier\"]\n                        alert_data[\"incident_id\"] = alert[\"additional_properties\"][\"incidentNumber\"]\n                        incidents_list.append(int(alert_data[\"incident_id\"]))\n                        siemplify_alerts.append(alert_data)\n        \n        filtered_incidents = []        \n        for incident in incidents:\n            if incident[\"properties\"][\"incidentNumber\"] in incidents_list:\n                filtered_incidents.append(incident)\n        \n        siemplify.LOGGER.info(\"Fetching Entities for relevant Azure Sentinel Incidents\")\n        entities_to_sync = []\n        \n        for incident in filtered_incidents:\n            \n            entities_data = {}\n            entities = manager.get_incident_entities_sync(incident[\"name\"])\n            if entities:\n                alert_data = {}\n                siemplify.LOGGER.info(f'Processing Entities for incident {incident[\"properties\"][\"incidentNumber\"]}')\n                target_entities = process_entities(entities,siemplify)\n                alert_data[\"entities\"] = target_entities\n                for alert in siemplify_alerts:\n                    if incident[\"properties\"][\"incidentNumber\"] == int(alert[\"incident_id\"]):\n                        alert_data[\"case_id\"] = alert[\"case_id\"]\n                        alert_data[\"identifier\"] = alert[\"identifier\"]\n                entities_to_sync.append(alert_data)        \n            else:\n                siemplify.LOGGER.info(f'No entities found for incident {incident[\"properties\"][\"incidentNumber\"]}')\n        \n        siemplify.LOGGER.info(f'Creating entities in {len(entities_to_sync)} alerts in Siemplify')\n        \n        for data in entities_to_sync:\n            result = create_entities(data, environment, siemplify)\n            if not result:\n                siemplify.LOGGER.info(\"Entities creation Failed\")\n        \n        \n        new_timestamp = utc_now()\n        siemplify.LOGGER.info(f\"Update Job last execution timestamp to {new_timestamp}\")\n        new_timestamp = datetime.datetime.timestamp(new_timestamp) *1000\n            \n            \n        siemplify.save_timestamp(new_timestamp=int(new_timestamp))\n\n            \n\n\n    except Exception as e:\n        siemplify.LOGGER.error(\"General error performing Job {}\".format(SCRIPT_NAME))\n        siemplify.LOGGER.exception(e)\n        raise\n\n    siemplify.end_script()\n\n\nif __name__ == \"__main__\":\n    main()",
    "creator": "7a7f9e2c-7774-4221-8558-986f5708fd17",
    "description": "Will create new entities in Siemplify Alerts from AS incidents",
    "isEnabled": true,
    "isCustom": true,
    "version": 250,
    "parameters": [
        {
            "id": 19,
            "isMandatory": true,
            "name": "Environment",
            "type": 2,
            "value": "Default Environment"
        },
        {
            "id": 20,
            "isMandatory": false,
            "name": "Instance Name",
            "type": 2,
            "value": ""
        },
        {
            "id": 21,
            "isMandatory": true,
            "name": "Hours Back",
            "type": 1,
            "value": "24"
        },
        {
            "id": 22,
            "isMandatory": true,
            "name": "Sync Tags",
            "type": 2,
            "value": "Azure Sentinel"
        }
    ],
    "runIntervalInSeconds": 60,
    "creationTime": "2022-11-25T13:31:30.597Z",
    "lastModificationTime": "2022-11-25T13:31:30.597Z",
    "isSystemJob": false
}